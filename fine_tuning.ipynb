{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['13020220048', '13020220049', '13020220050', '13020220051', '13020220052', '13020220053', '13020220054', '13020220056', '13020220148', '13020220152', '13020220155', '13020220157', '13020220159', '13020220160', '13020220167', '13020220173', '13020220303', '13020220304', '13020220305']\n",
      "['13020220048', '13020220049', '13020220050', '13020220051', '13020220052', '13020220053', '13020220054', '13020220056', '13020220148', '13020220152', '13020220155', '13020220157', '13020220159', '13020220160', '13020220167', '13020220173', '13020220303', '13020220304', '13020220305']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data Science\\FRP\\AttendanceFaceRecognition\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Data Science\\FRP\\AttendanceFaceRecognition\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 2.969\n",
      "[1,    20] loss: 2.799\n",
      "[1,    30] loss: 2.627\n",
      "[1,    40] loss: 2.445\n",
      "[1,    50] loss: 2.337\n",
      "[1,    60] loss: 2.181\n",
      "[1,    70] loss: 2.041\n",
      "[1,    80] loss: 1.928\n",
      "[1,    90] loss: 1.833\n",
      "[1,   100] loss: 1.759\n",
      "[1,   110] loss: 1.660\n",
      "[1,   120] loss: 1.735\n",
      "[1,   130] loss: 1.598\n",
      "[1,   140] loss: 1.544\n",
      "[1,   150] loss: 1.538\n",
      "[2,    10] loss: 1.391\n",
      "[2,    20] loss: 1.373\n",
      "[2,    30] loss: 1.374\n",
      "[2,    40] loss: 1.240\n",
      "[2,    50] loss: 1.178\n",
      "[2,    60] loss: 1.209\n",
      "[2,    70] loss: 1.183\n",
      "[2,    80] loss: 1.148\n",
      "[2,    90] loss: 1.183\n",
      "[2,   100] loss: 1.103\n",
      "[2,   110] loss: 1.091\n",
      "[2,   120] loss: 1.095\n",
      "[2,   130] loss: 0.957\n",
      "[2,   140] loss: 1.023\n",
      "[2,   150] loss: 0.963\n",
      "[3,    10] loss: 0.936\n",
      "[3,    20] loss: 0.900\n",
      "[3,    30] loss: 0.940\n",
      "[3,    40] loss: 0.920\n",
      "[3,    50] loss: 0.908\n",
      "[3,    60] loss: 0.924\n",
      "[3,    70] loss: 0.806\n",
      "[3,    80] loss: 0.816\n",
      "[3,    90] loss: 0.833\n",
      "[3,   100] loss: 0.816\n",
      "[3,   110] loss: 0.858\n",
      "[3,   120] loss: 0.808\n",
      "[3,   130] loss: 0.804\n",
      "[3,   140] loss: 0.828\n",
      "[3,   150] loss: 0.813\n",
      "[4,    10] loss: 0.717\n",
      "[4,    20] loss: 0.716\n",
      "[4,    30] loss: 0.710\n",
      "[4,    40] loss: 0.736\n",
      "[4,    50] loss: 0.724\n",
      "[4,    60] loss: 0.691\n",
      "[4,    70] loss: 0.684\n",
      "[4,    80] loss: 0.779\n",
      "[4,    90] loss: 0.720\n",
      "[4,   100] loss: 0.623\n",
      "[4,   110] loss: 0.651\n",
      "[4,   120] loss: 0.728\n",
      "[4,   130] loss: 0.697\n",
      "[4,   140] loss: 0.657\n",
      "[4,   150] loss: 0.635\n",
      "[5,    10] loss: 0.628\n",
      "[5,    20] loss: 0.636\n",
      "[5,    30] loss: 0.538\n",
      "[5,    40] loss: 0.611\n",
      "[5,    50] loss: 0.581\n",
      "[5,    60] loss: 0.577\n",
      "[5,    70] loss: 0.631\n",
      "[5,    80] loss: 0.583\n",
      "[5,    90] loss: 0.648\n",
      "[5,   100] loss: 0.552\n",
      "[5,   110] loss: 0.588\n",
      "[5,   120] loss: 0.620\n",
      "[5,   130] loss: 0.601\n",
      "[5,   140] loss: 0.539\n",
      "[5,   150] loss: 0.552\n",
      "[6,    10] loss: 0.533\n",
      "[6,    20] loss: 0.565\n",
      "[6,    30] loss: 0.475\n",
      "[6,    40] loss: 0.547\n",
      "[6,    50] loss: 0.605\n",
      "[6,    60] loss: 0.519\n",
      "[6,    70] loss: 0.512\n",
      "[6,    80] loss: 0.516\n",
      "[6,    90] loss: 0.565\n",
      "[6,   100] loss: 0.552\n",
      "[6,   110] loss: 0.487\n",
      "[6,   120] loss: 0.491\n",
      "[6,   130] loss: 0.466\n",
      "[6,   140] loss: 0.538\n",
      "[6,   150] loss: 0.483\n",
      "[7,    10] loss: 0.471\n",
      "[7,    20] loss: 0.499\n",
      "[7,    30] loss: 0.542\n",
      "[7,    40] loss: 0.454\n",
      "[7,    50] loss: 0.466\n",
      "[7,    60] loss: 0.429\n",
      "[7,    70] loss: 0.438\n",
      "[7,    80] loss: 0.449\n",
      "[7,    90] loss: 0.520\n",
      "[7,   100] loss: 0.425\n",
      "[7,   110] loss: 0.521\n",
      "[7,   120] loss: 0.487\n",
      "[7,   130] loss: 0.451\n",
      "[7,   140] loss: 0.443\n",
      "[7,   150] loss: 0.479\n",
      "[8,    10] loss: 0.429\n",
      "[8,    20] loss: 0.476\n",
      "[8,    30] loss: 0.443\n",
      "[8,    40] loss: 0.534\n",
      "[8,    50] loss: 0.388\n",
      "[8,    60] loss: 0.482\n",
      "[8,    70] loss: 0.380\n",
      "[8,    80] loss: 0.405\n",
      "[8,    90] loss: 0.441\n",
      "[8,   100] loss: 0.396\n",
      "[8,   110] loss: 0.433\n",
      "[8,   120] loss: 0.410\n",
      "[8,   130] loss: 0.383\n",
      "[8,   140] loss: 0.354\n",
      "[8,   150] loss: 0.435\n",
      "[9,    10] loss: 0.377\n",
      "[9,    20] loss: 0.438\n",
      "[9,    30] loss: 0.392\n",
      "[9,    40] loss: 0.385\n",
      "[9,    50] loss: 0.386\n",
      "[9,    60] loss: 0.396\n",
      "[9,    70] loss: 0.432\n",
      "[9,    80] loss: 0.393\n",
      "[9,    90] loss: 0.420\n",
      "[9,   100] loss: 0.415\n",
      "[9,   110] loss: 0.381\n",
      "[9,   120] loss: 0.373\n",
      "[9,   130] loss: 0.367\n",
      "[9,   140] loss: 0.365\n",
      "[9,   150] loss: 0.378\n",
      "[10,    10] loss: 0.369\n",
      "[10,    20] loss: 0.388\n",
      "[10,    30] loss: 0.380\n",
      "[10,    40] loss: 0.385\n",
      "[10,    50] loss: 0.373\n",
      "[10,    60] loss: 0.388\n",
      "[10,    70] loss: 0.419\n",
      "[10,    80] loss: 0.410\n",
      "[10,    90] loss: 0.335\n",
      "[10,   100] loss: 0.352\n",
      "[10,   110] loss: 0.345\n",
      "[10,   120] loss: 0.380\n",
      "[10,   130] loss: 0.347\n",
      "[10,   140] loss: 0.360\n",
      "[10,   150] loss: 0.324\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "\n",
    "# Define transforms for both training and testing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Define the paths to the train and test data directories\n",
    "train_data_dir = 'Dataset/train/' \n",
    "test_data_dir = 'Dataset/test/'    \n",
    "\n",
    "# Load train and test datasets using ImageFolder\n",
    "train_dataset = ImageFolder(root=train_data_dir, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_data_dir, transform=transform)\n",
    "\n",
    "# Define batch size for dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "# Create dataloaders for train and test datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(train_loader.dataset.classes)\n",
    "print(test_loader.dataset.classes)\n",
    "\n",
    "# Load pre-trained ResNet model\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the last fully connected layer\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the last fully connected layer for binary classification (2 output classes)\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, len(train_loader.dataset.classes))\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:  # Print every 10 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 93.43 %\n",
      "Precision on test set: 0.94\n",
      "Recall on test set: 0.93\n",
      "F1-score on test set: 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "resnet.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = resnet(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print('Accuracy on test set: %.2f %%' % accuracy)\n",
    "print('Precision on test set: %.2f' % precision)\n",
    "print('Recall on test set: %.2f' % recall)\n",
    "print('F1-score on test set: %.2f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(resnet.state_dict(), 'resnet_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
