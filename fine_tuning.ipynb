{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['13020220048', '13020220049', '13020220050', '13020220051', '13020220052', '13020220053', '13020220054', '13020220056', '13020220148', '13020220152', '13020220155', '13020220157', '13020220159', '13020220160', '13020220167', '13020220173', '13020220303', '13020220304', '13020220305']\n",
      "['13020220048', '13020220049', '13020220050', '13020220051', '13020220052', '13020220053', '13020220054', '13020220056', '13020220148', '13020220152', '13020220155', '13020220157', '13020220159', '13020220160', '13020220167', '13020220173', '13020220303', '13020220304', '13020220305']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data Science\\FRP\\AttendanceFaceRecognition\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Data Science\\FRP\\AttendanceFaceRecognition\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 2.969\n",
      "[1,    20] loss: 2.799\n",
      "[1,    30] loss: 2.627\n",
      "[1,    40] loss: 2.445\n",
      "[1,    50] loss: 2.337\n",
      "[1,    60] loss: 2.181\n",
      "[1,    70] loss: 2.041\n",
      "[1,    80] loss: 1.928\n",
      "[1,    90] loss: 1.833\n",
      "[1,   100] loss: 1.759\n",
      "[1,   110] loss: 1.660\n",
      "[1,   120] loss: 1.735\n",
      "[1,   130] loss: 1.598\n",
      "[1,   140] loss: 1.544\n",
      "[1,   150] loss: 1.538\n",
      "[2,    10] loss: 1.391\n",
      "[2,    20] loss: 1.373\n",
      "[2,    30] loss: 1.374\n",
      "[2,    40] loss: 1.240\n",
      "[2,    50] loss: 1.178\n",
      "[2,    60] loss: 1.209\n",
      "[2,    70] loss: 1.183\n",
      "[2,    80] loss: 1.148\n",
      "[2,    90] loss: 1.183\n",
      "[2,   100] loss: 1.103\n",
      "[2,   110] loss: 1.091\n",
      "[2,   120] loss: 1.095\n",
      "[2,   130] loss: 0.957\n",
      "[2,   140] loss: 1.023\n",
      "[2,   150] loss: 0.963\n",
      "[3,    10] loss: 0.936\n",
      "[3,    20] loss: 0.900\n",
      "[3,    30] loss: 0.940\n",
      "[3,    40] loss: 0.920\n",
      "[3,    50] loss: 0.908\n",
      "[3,    60] loss: 0.924\n",
      "[3,    70] loss: 0.806\n",
      "[3,    80] loss: 0.816\n",
      "[3,    90] loss: 0.833\n",
      "[3,   100] loss: 0.816\n",
      "[3,   110] loss: 0.858\n",
      "[3,   120] loss: 0.808\n",
      "[3,   130] loss: 0.804\n",
      "[3,   140] loss: 0.828\n",
      "[3,   150] loss: 0.813\n",
      "[4,    10] loss: 0.717\n",
      "[4,    20] loss: 0.716\n",
      "[4,    30] loss: 0.710\n",
      "[4,    40] loss: 0.736\n",
      "[4,    50] loss: 0.724\n",
      "[4,    60] loss: 0.691\n",
      "[4,    70] loss: 0.684\n",
      "[4,    80] loss: 0.779\n",
      "[4,    90] loss: 0.720\n",
      "[4,   100] loss: 0.623\n",
      "[4,   110] loss: 0.651\n",
      "[4,   120] loss: 0.728\n",
      "[4,   130] loss: 0.697\n",
      "[4,   140] loss: 0.657\n",
      "[4,   150] loss: 0.635\n",
      "[5,    10] loss: 0.628\n",
      "[5,    20] loss: 0.636\n",
      "[5,    30] loss: 0.538\n",
      "[5,    40] loss: 0.611\n",
      "[5,    50] loss: 0.581\n",
      "[5,    60] loss: 0.577\n",
      "[5,    70] loss: 0.631\n",
      "[5,    80] loss: 0.583\n",
      "[5,    90] loss: 0.648\n",
      "[5,   100] loss: 0.552\n",
      "[5,   110] loss: 0.588\n",
      "[5,   120] loss: 0.620\n",
      "[5,   130] loss: 0.601\n",
      "[5,   140] loss: 0.539\n",
      "[5,   150] loss: 0.552\n",
      "[6,    10] loss: 0.533\n",
      "[6,    20] loss: 0.565\n",
      "[6,    30] loss: 0.475\n",
      "[6,    40] loss: 0.547\n",
      "[6,    50] loss: 0.605\n",
      "[6,    60] loss: 0.519\n",
      "[6,    70] loss: 0.512\n",
      "[6,    80] loss: 0.516\n",
      "[6,    90] loss: 0.565\n",
      "[6,   100] loss: 0.552\n",
      "[6,   110] loss: 0.487\n",
      "[6,   120] loss: 0.491\n",
      "[6,   130] loss: 0.466\n",
      "[6,   140] loss: 0.538\n",
      "[6,   150] loss: 0.483\n",
      "[7,    10] loss: 0.471\n",
      "[7,    20] loss: 0.499\n",
      "[7,    30] loss: 0.542\n",
      "[7,    40] loss: 0.454\n",
      "[7,    50] loss: 0.466\n",
      "[7,    60] loss: 0.429\n",
      "[7,    70] loss: 0.438\n",
      "[7,    80] loss: 0.449\n",
      "[7,    90] loss: 0.520\n",
      "[7,   100] loss: 0.425\n",
      "[7,   110] loss: 0.521\n",
      "[7,   120] loss: 0.487\n",
      "[7,   130] loss: 0.451\n",
      "[7,   140] loss: 0.443\n",
      "[7,   150] loss: 0.479\n",
      "[8,    10] loss: 0.429\n",
      "[8,    20] loss: 0.476\n",
      "[8,    30] loss: 0.443\n",
      "[8,    40] loss: 0.534\n",
      "[8,    50] loss: 0.388\n",
      "[8,    60] loss: 0.482\n",
      "[8,    70] loss: 0.380\n",
      "[8,    80] loss: 0.405\n",
      "[8,    90] loss: 0.441\n",
      "[8,   100] loss: 0.396\n",
      "[8,   110] loss: 0.433\n",
      "[8,   120] loss: 0.410\n",
      "[8,   130] loss: 0.383\n",
      "[8,   140] loss: 0.354\n",
      "[8,   150] loss: 0.435\n",
      "[9,    10] loss: 0.377\n",
      "[9,    20] loss: 0.438\n",
      "[9,    30] loss: 0.392\n",
      "[9,    40] loss: 0.385\n",
      "[9,    50] loss: 0.386\n",
      "[9,    60] loss: 0.396\n",
      "[9,    70] loss: 0.432\n",
      "[9,    80] loss: 0.393\n",
      "[9,    90] loss: 0.420\n",
      "[9,   100] loss: 0.415\n",
      "[9,   110] loss: 0.381\n",
      "[9,   120] loss: 0.373\n",
      "[9,   130] loss: 0.367\n",
      "[9,   140] loss: 0.365\n",
      "[9,   150] loss: 0.378\n",
      "[10,    10] loss: 0.369\n",
      "[10,    20] loss: 0.388\n",
      "[10,    30] loss: 0.380\n",
      "[10,    40] loss: 0.385\n",
      "[10,    50] loss: 0.373\n",
      "[10,    60] loss: 0.388\n",
      "[10,    70] loss: 0.419\n",
      "[10,    80] loss: 0.410\n",
      "[10,    90] loss: 0.335\n",
      "[10,   100] loss: 0.352\n",
      "[10,   110] loss: 0.345\n",
      "[10,   120] loss: 0.380\n",
      "[10,   130] loss: 0.347\n",
      "[10,   140] loss: 0.360\n",
      "[10,   150] loss: 0.324\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define transforms for both training and testing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Define the paths to the train and test data directories\n",
    "train_data_dir = 'Dataset/train/' \n",
    "test_data_dir = 'Dataset/test/'    \n",
    "\n",
    "# Load train and test datasets using ImageFolder\n",
    "train_dataset = ImageFolder(root=train_data_dir, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_data_dir, transform=transform)\n",
    "\n",
    "# Define batch size for dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "# Create dataloaders for train and test datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(train_loader.dataset.classes)\n",
    "print(test_loader.dataset.classes)\n",
    "\n",
    "# Load pre-trained ResNet model\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the last fully connected layer\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the last fully connected layer for binary classification (2 output classes)\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, len(train_loader.dataset.classes))\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:  # Print every 10 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 93.43 %\n",
      "Precision on test set: 0.94\n",
      "Recall on test set: 0.93\n",
      "F1-score on test set: 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "resnet.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = resnet(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print('Accuracy on test set: %.2f %%' % accuracy)\n",
    "print('Precision on test set: %.2f' % precision)\n",
    "print('Recall on test set: %.2f' % recall)\n",
    "print('F1-score on test set: %.2f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(resnet.state_dict(), 'resnet_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset folder structure and metadata file generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "# Define paths\n",
    "dataset_root = 'Eval_dataset'\n",
    "metadata_file = 'metadata.csv'\n",
    "\n",
    "# Create dataset root directory\n",
    "if not os.path.exists(dataset_root):\n",
    "    os.makedirs(dataset_root)\n",
    "\n",
    "# Function to generate similar pairs\n",
    "def generate_similar_pairs(person_folders):\n",
    "    similar_pairs = []\n",
    "    for folder in person_folders:\n",
    "        images = os.listdir(os.path.join(dataset_root, folder))\n",
    "        for i, img1 in enumerate(images):\n",
    "            for j, img2 in enumerate(images):\n",
    "                if i < j:\n",
    "                    similar_pairs.append((os.path.join(folder, img1), os.path.join(folder, img2), 1))\n",
    "    return similar_pairs\n",
    "\n",
    "# Function to generate dissimilar pairs\n",
    "def generate_dissimilar_pairs(person_folders):\n",
    "    dissimilar_pairs = []\n",
    "    for i, folder1 in enumerate(person_folders):\n",
    "        for j, folder2 in enumerate(person_folders):\n",
    "            if i < j:\n",
    "                images1 = os.listdir(os.path.join(dataset_root, folder1))\n",
    "                images2 = os.listdir(os.path.join(dataset_root, folder2))\n",
    "                for img1 in images1:\n",
    "                    for img2 in images2:\n",
    "                        dissimilar_pairs.append((os.path.join(folder1, img1), os.path.join(folder2, img2), 0))\n",
    "    return dissimilar_pairs\n",
    "\n",
    "# Get list of person folders\n",
    "person_folders = os.listdir(dataset_root)\n",
    "\n",
    "# Generate pairs\n",
    "similar_pairs = generate_similar_pairs(person_folders)\n",
    "dissimilar_pairs = generate_dissimilar_pairs(person_folders)\n",
    "\n",
    "# Combine pairs and shuffle\n",
    "pairs = similar_pairs + dissimilar_pairs\n",
    "random.shuffle(pairs)\n",
    "\n",
    "# Write metadata to CSV file\n",
    "with open(metadata_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Image1_Path', 'Image2_Path', 'Label'])\n",
    "    for pair in pairs:\n",
    "        writer.writerow(pair)\n",
    "\n",
    "print(f\"Dataset folder structure and metadata file generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6575718153370135\n"
     ]
    }
   ],
   "source": [
    "# Evaluate finetuned model\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load the fine-tuned ResNet model\n",
    "loaded_model = models.resnet50(pretrained=False)  # Instantiate the same architecture\n",
    "loaded_model.fc = nn.Linear(num_ftrs, len(train_loader.dataset.classes)) \n",
    "loaded_model.load_state_dict(torch.load('resnet_model.pth'))\n",
    "loaded_model.eval()  # Set the model to evaluation mode\n",
    "correct_predictions = 0  # Initialize the variable to count correct predictions\n",
    "\n",
    "# Define transformations for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to load and preprocess image\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image)\n",
    "    return image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Load metadata CSV file\n",
    "metadata_file = 'Metadata.csv'\n",
    "with open(metadata_file, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        image1_path = row['Image1_Path']\n",
    "        image2_path = row['Image2_Path']\n",
    "        label = int(row['Label'])\n",
    "\n",
    "        # Load and preprocess images\n",
    "        image1 = load_image(os.path.join('Eval_dataset', image1_path))\n",
    "        image2 = load_image(os.path.join('Eval_dataset', image2_path))\n",
    "\n",
    "        # Generate embeddings\n",
    "        with torch.no_grad():\n",
    "            embedding1 = resnet(image1)\n",
    "            embedding2 = resnet(image2)\n",
    "\n",
    "        # Compute similarity score (cosine similarity)\n",
    "        similarity_score = torch.nn.functional.cosine_similarity(embedding1, embedding2, dim=1).item()\n",
    "\n",
    "        # Classify as similar (1) or dissimilar (0) based on threshold\n",
    "        threshold = 0.5  # Set your threshold here\n",
    "        prediction = 1 if similarity_score >= threshold else 0\n",
    "\n",
    "        # Compare with ground truth label and compute evaluation metrics\n",
    "        if prediction == label:\n",
    "            correct_predictions += 1\n",
    "\n",
    "# Compute evaluation metrics\n",
    "total_pairs = len(pairs)\n",
    "accuracy = correct_predictions / total_pairs\n",
    "# Compute other evaluation metrics as needed\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "# Print other evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4673001577818356\n"
     ]
    }
   ],
   "source": [
    "# Evaluate baseline\n",
    "import csv\n",
    "import os\n",
    "import dlib\n",
    "import face_recognition\n",
    "\n",
    "# Load metadata CSV file\n",
    "metadata_file = 'Metadata.csv'\n",
    "correct_predictions = 0  # Initialize the variable to count correct predictions\n",
    "\n",
    "# Initialize face detector and face recognition model\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "face_recog_model = 'hog'  # 'hog' for CPU-based model, 'cnn' for GPU-based model\n",
    "\n",
    "with open(metadata_file, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        image1_path = row['Image1_Path']\n",
    "        image2_path = row['Image2_Path']\n",
    "        label = int(row['Label'])\n",
    "\n",
    "        # Load images\n",
    "        image1 = face_recognition.load_image_file(os.path.join('Eval_dataset', image1_path))\n",
    "        image2 = face_recognition.load_image_file(os.path.join('Eval_dataset', image2_path))\n",
    "\n",
    "        # Detect faces and extract embeddings\n",
    "        face_locations1 = face_recognition.face_locations(image1, model=face_recog_model)\n",
    "        face_locations2 = face_recognition.face_locations(image2, model=face_recog_model)\n",
    "        \n",
    "        if len(face_locations1) > 0 and len(face_locations2) > 0:\n",
    "            face_encoding1 = face_recognition.face_encodings(image1, face_locations1)[0]\n",
    "            face_encoding2 = face_recognition.face_encodings(image2, face_locations2)[0]\n",
    "\n",
    "            # Compute similarity score (e.g., Euclidean distance)\n",
    "            similarity_score = face_recognition.face_distance([face_encoding1], face_encoding2)[0]\n",
    "\n",
    "            # Classify as similar (1) or dissimilar (0) based on threshold\n",
    "            threshold = 0.5  # Set your threshold here\n",
    "            prediction = 1 if similarity_score <= threshold else 0\n",
    "\n",
    "            # Compare with ground truth label and compute evaluation metrics\n",
    "            if prediction == label:\n",
    "                correct_predictions += 1\n",
    "\n",
    "            total_pairs += 1\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = correct_predictions / total_pairs\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEW TRAINING WITH VIZ\n",
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "\n",
    "# Define transforms for both training and testing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Define the paths to the train and test data directories\n",
    "train_data_dir = 'Dataset/train/' \n",
    "test_data_dir = 'Dataset/test/'    \n",
    "\n",
    "# Load train and test datasets using ImageFolder\n",
    "train_dataset = ImageFolder(root=train_data_dir, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_data_dir, transform=transform)\n",
    "\n",
    "# Define batch size for dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "# Create dataloaders for train and test datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(train_loader.dataset.classes)\n",
    "print(test_loader.dataset.classes)\n",
    "\n",
    "# Load pre-trained ResNet model\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the last fully connected layer\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the last fully connected layer for binary classification (2 output classes)\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, len(train_loader.dataset.classes))\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Lists to store training and validation metrics\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "# Define your training and validation loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    resnet.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_loss_history.append(train_loss)\n",
    "\n",
    "    # Validation loop\n",
    "    resnet.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = resnet(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = val_running_loss / len(test_loader)\n",
    "    val_loss_history.append(val_loss)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    accuracy_history.append(accuracy)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Training Loss: {train_loss:.4f}, \"\n",
    "          f\"Validation Loss: {val_loss:.4f}, \"\n",
    "          f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss_history, label='Training Loss')\n",
    "plt.plot(val_loss_history, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracy_history, label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
